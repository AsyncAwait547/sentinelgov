version: '3.8'

services:
  # ─────────────────────────────────────────────────────────
  # 1. Message Broker (Real-time Event Streaming)
  # ─────────────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 5

  # ─────────────────────────────────────────────────────────
  # 2. Immutable Ledger / TSDB (Persistence)
  # ─────────────────────────────────────────────────────────
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: sentinel
      POSTGRES_PASSWORD: sentinel_password
      POSTGRES_DB: sentinelgov
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U sentinel" ]
      interval: 5s
      timeout: 3s
      retries: 5

  # ─────────────────────────────────────────────────────────
  # 3. Sentinel AI Risk Predictor (Python FastAPI)
  # ─────────────────────────────────────────────────────────
  ml-service:
    build:
      context: ./ml-service
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - MODEL_THRESHOLD=0.75
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # ─────────────────────────────────────────────────────────
  # 4. Sentinel Orchestration Backend (Node.js) & Frontend
  # ─────────────────────────────────────────────────────────
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379
      - DB_URL=postgresql://sentinel:sentinel_password@postgres:5432/sentinelgov
      - ML_SERVICE_URL=http://ml-service:8000
      - OPENWEATHERMAP_API_KEY=${OPENWEATHERMAP_API_KEY:-}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ml-service:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/api/health" ]
      interval: 10s
      timeout: 5s
      start_period: 15s
      retries: 3

volumes:
  redis_data:
  pg_data:
